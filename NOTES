-*- Mode: Text -*

Beta Network

- Memory node (also `mem node' or `m node'). A `beta memory'
  node. Can be hashed or unhashed. Creates and stores |token| objects?

- Positive node (also `pos node' and `p node'). Can be hashed or unhashed.

- MP node. Can be hashed or unhashed. Combined `memory node' and
  `positive node' to save space? From the `node_[left|right]_addition'
  routines, it appears that this is the case...

- Negative node. Can be hashed or unhashed.

- Dummy top node. Parents all of the other beta nodes in the network.

- Dummy matches node.

- CN (conjunctive negative) node, and CN-partner node.

- P (production?) node. 

hashed versus unhashed beta memory nodes? Why are some hashed and
others aren't? All that appears to be different is the computation of
the hash value that's used to find appropriate tokens...

A |token| appears to be the partially instantiated rule. There is a
`dummy top token' that is assigned to the `dummy top node' which is
the eventual ancestor of every beta node. Each token is hashed into
the `left hashtable'.

What is the difference between `left' and `right' memory?

- the `left addition' routines all take a |rete_node|, a |token|, and
  a |wme|; the `right addition' routines take a |rete_node| and a |wme|,
  but not a |token|. What's going on here?

- After adding a new |wme| to alpha memory, we call the `right node
  addition routine' for each beta node that hangs off of the alpha
  memory.

- The beta node addition routines only call the `left node addition
  routines'.

- Interestingly, there is no `right node addition routine' for a
  memory node; however, there *is* a `right node addition routine' for
  an MP node. Here's how they break down...

  DUMMY_TOP_BNODE           no addition routines
  DUMMY_MATCHES_BNODE       left addition routine only
  [UNHASHED_]MEMORY_BNODE   left only
  [UNHASHED_]POSITIVE_BNODE right only
  [UNHASHED_]MP_BNODE       left & right
  [UNHASHED_]NEGATIVE_BNODE left & right
  CN_[PARTNER_]BNODE        left only
  P_BNODE                   left only

- So, is the alpha network `right memory' and the beta network `left
  memory'?

What is `unlinking'?

Starting to understand how a production is converted into beta nodes a
bit better. Specifically, how `variable bindings' work. So we parse
the list of conditions, and as we do so, we both create beta nodes and
build up a list of `variable bindings'. A `variable binding' is simply
a `field' (the id, attr, or value) and a `depth' in the beta network.

When we make a new condition node, we `sparsely' beind variables
before creating the rete tests (so that, at worst, if a variable is
not yet bound, it the test will be `scoped' to the current beta
node). Then, after the condition node has been created, we formally
push the variables onto the stack (so that subsequent users of these
variables can find them).

After we're done parsing the list of conditions, we remove all of the
variable bindings. (Which, BTW, are stored in the `symbol table',
making this part of the code non-reentrant.)

---

For a condition like `(state <s>)', Soar is creating a conjunctive
condition whose first part is a `goal id' test, and whose second part
is an `equality test'. It looks like how this works then is that the
`goal id' part of the test checks the WME's `id' field to see if the
identifier is actually a goal, and the second part of the test binds
the goal to a variable. Tricky!

---

Hack for computing code size...

h8300-hitachi-hms-objdump --section-headers *.o |\
 grep .text |\
 awk '{ print $3; }' |\
 perl -e 'while (<>) { $sum += hex($_); } print "$sum\n";'

---

I was thinking that it might be possible to shrink WMEs and generally
save space by having a WME just maintain its `value', and get its `id'
and `attr' from its slot...

  struct wme {
    struct slot* slot;
    symbol_t     value;
    ...
  };

You could then enumerate all of the WMEs in the system by enumerating
the agent's `slots' hashtable. The only problem with this scheme are
WMEs that are created `outside' the RETE network; e.g., by somebody
doing brain surgery on the agent.

---

CHUNKING

  1. Collect all ``result'' preferences created by an instantiation,
     that is, preferences for superstates,
     |get_results_for_instantiation()| in chunk.c does this.

  2. For each preference, call |backtrace_through_instantiation()|
     with the instantiation that created the preference. (Which is a
     bit weird, because shouldn't all the preferences have been
     created by the same instantiation?)

  3. Repeatedly |trace_locals()|, |trace_grounded_potentials()|, and
     |trace_ungrounded_potentials()| until there are no more (?)
     ungrounded potentials.

  4. Build the chunk conditions.

  backtrace_through_instantiation(inst, grounds_level, trace_cond, indent)

    1. Bail if we've already backtraced this |inst|; otherwise, note
       that we've backtraced it.

    2. Mark the transitive closure of each higher goal that was tested
       in the ID field of a top-level positive condition.

Hmm. Interesting. We associate a level in the goal stack with each
identifier: this is important for chunking. Presumably identifiers
``created'' in a subgoal get ``promoted'' to the goal-level to which
they were returned.

Okay, so |preference| is going to have to change. Instead of
maintaining a doubly-linked list of the preferences in the current
instantiation, it's going to need a back-pointer to the instantiation
that created it. From the instantiation, we can get the token, and
from the token, I think we can walk back up through the identifiers
that we tested. Hrm, but how to get from _those_ identifiers to the
preference that created it? (Do we need to?)
